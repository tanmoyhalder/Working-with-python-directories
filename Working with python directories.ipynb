{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1334126\\Desktop\\DataCamp Learnings\\Python Learnings\\Week1-Python\\Week1-Python-Assignment\n"
     ]
    }
   ],
   "source": [
    "## Checking current working directory\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1334126\\Desktop\\DataCamp Learnings\\Python Learnings\n"
     ]
    }
   ],
   "source": [
    "## Changing current working directory\n",
    "os.chdir('C:\\\\Users\\\\1334126\\\\Desktop\\\\DataCamp Learnings\\\\Python Learnings')\n",
    "print(os.getcwd())\n",
    "\n",
    "## Can't use directly 'C:\\Users\\1334126'. Instead use either\n",
    "\n",
    "# 'C:\\\\Users\\\\1334126'      OR\n",
    "# 'C:/Users/1334126'        OR\n",
    "#  r 'C:\\Users\\1334126'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in function listdir>\n",
      "['all_data-20190516T175626Z-001.zip', 'Python Learnings', 'Week1-Python']\n"
     ]
    }
   ],
   "source": [
    "## To check the content of a directory\n",
    "pathname = 'C:\\\\Users\\\\1334126\\\\Desktop\\\\DataCamp Learnings\\\\Python Learnings'\n",
    "os.listdir(pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Users\\\\1334126\\\\Desktop\\\\DataCamp Learnings\\\\Python Learnings\\\\Week1-Python\\\\Week1-Python-Assignment',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\python37.zip',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\1334126\\\\.ipython']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking th elist of path that python would search in if you are are importing a module or trying to open a file \n",
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To add a certain path in the path list, follow the below steps\n",
    "\n",
    "1. In Windows search bar, serch for \"Edit ENvironment Variables for your account\"\n",
    "2. Open the link\n",
    "3. CLick on New\n",
    "4. Write PYTHONPATH (in caps) in the variable name\n",
    "5. Type you path in the variable value\n",
    "6. put ';' (semicolon) at the end of the path name\n",
    "7. Press Ok and exit\n",
    "8. Close the kernel and reopen it\n",
    "9. type import sys and sys.path (you will be able to see your pathname in the list of python paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative and Absolute path\n",
    "\n",
    "These are two very important concepts in python, specially when you will import different files/ modules existing in different directories.\n",
    "\n",
    "Absoulte Path: This is the full path name. For example, \"C:\\Users\\1334126\\Desktop\\DataCamp Learnings\\Python Learnings\\Week1-Python\"\n",
    "               This tells you the full path where your file is stored.\n",
    "       \n",
    "Suppose, you are in folder 'A' and this is your current working directory. You can easily open a file (say file1) existing in this folder \n",
    "with 'open(file)' function. But, if you want to open another file (say file2) that is in 'B' folder that is one level up from your current \n",
    "working directory 'A'. What do you do? Folder 'B' contains file2 as well as folder 'A'.\n",
    "\n",
    "Here comes the concept of Relative path. You can access the file2 in folder 'B' directly from folder 'A'. Folder 'B' is one level up.\n",
    "So if you want to access files in that folder, you will have to go one level up. You can do this by using \"..\\\\\" before your current path.\n",
    "So, to open file2 in folder 'B' you type \n",
    "\n",
    "open('..\\\\file2.txt', 'r').read()\n",
    "\n",
    "See below for another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1334126\\Desktop\\DataCamp Learnings\\Python Learnings\\Week1-Python\n"
     ]
    }
   ],
   "source": [
    "## Relative \n",
    "os.chdir(r'C:\\Users\\1334126\\Desktop\\DataCamp Learnings\\Python Learnings\\Week1-Python')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can open a file (remember file1) in this current working directory 'data.txt' using the open function \n",
    "# without mentioneing any path\n",
    "\n",
    "f = open('data.txt', 'r')\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It uses all of the data for training while classifying a new data point or instance. KNN is a non-parametric learning algorithm, which means that it doesn't assume anything about the underlying data. \n",
      "\n",
      "It is one of the simplest of all the supervised machine learning algorithms. It simply calculates the distance of a new data point to all other training data points.\n",
      "It then selects the K-nearest data points, where K can be any integer. Finally it assigns the data point to the class to which the majority of the K data points belong.\n",
      "\n",
      "\n",
      "\n",
      "Cons\n",
      "The KNN algorithm doesn't work well with high dimensional data because with large number of dimensions, it becomes difficult for the algorithm to calculate distance in each dimension.\n",
      "The KNN algorithm has a high prediction cost for large datasets. This is because in large datasets the cost of calculating distance between new point and each existing point becomes higher.\n",
      "Finally, the KNN algorithm doesn't work well with categorical features since it is difficult to find the distance between dimensions with categorical features.\n",
      "\n",
      "\n",
      "On training data,if we choose K=1.it will always predict the y variable corresponding to that row,,because a point is closest to itself if K=1,thus cause overfitting\n",
      "\n",
      "If K is too large \n",
      "\n",
      "For validation set,error is high initially but reaches minima for a particular value of K.We need to predict that value of K\n",
      "\n",
      "\n",
      "KNN for regression\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "df = pd.read_csv('train.csv')\n",
      "df.head()\n",
      "\n",
      "\n",
      "df.isnull().sum()\n",
      "#missing values in Item_weight and Outlet_size needs to be imputed\n",
      "mean = df['Item_Weight'].mean() #imputing item_weight with mean\n",
      "df['Item_Weight'].fillna(mean, inplace =True)\n",
      "\n",
      "mode = df['Outlet_Size'].mode() #imputing outlet size with mode\n",
      "df['Outlet_Size'].fillna(mode[0], inplace =True)\n",
      "\n",
      "\n",
      "## Deal with categorical variables and drop the id columns \t\n",
      "df.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1, inplace=True)\n",
      "df = pd.get_dummies(df)\n",
      "\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "train , test = train_test_split(df, test_size = 0.3)\n",
      "\n",
      "x_train = train.drop('Item_Outlet_Sales', axis=1)\n",
      "y_train = train['Item_Outlet_Sales']\n",
      "\n",
      "x_test = test.drop('Item_Outlet_Sales', axis = 1)\n",
      "y_test = test['Item_Outlet_Sales']\n",
      "\n",
      "\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "scaler = MinMaxScaler(feature_range=(0, 1))\n",
      "\n",
      "x_train_scaled = scaler.fit_transform(x_train)\n",
      "x_train = pd.DataFrame(x_train_scaled)\n",
      "\n",
      "x_test_scaled = scaler.fit_transform(x_test)\n",
      "x_test = pd.DataFrame(x_test_scaled)\n",
      "\n",
      "\n",
      "from sklearn import neighbors\n",
      "from sklearn.metrics import mean_squared_error \n",
      "from math import sqrt\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "rmse_val = [] #to store rmse values for different k\n",
      "for K in range(20):\n",
      "    K = K+1\n",
      "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
      "\n",
      "    model.fit(x_train, y_train)  #fit the model\n",
      "    pred=model.predict(x_test) #make prediction on test set\n",
      "    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
      "    rmse_val.append(error) #store rmse values\n",
      "\n",
      "\n",
      "curve = pd.DataFrame(rmse_val) #elbow curve \n",
      "curve.plot()\n",
      "\n",
      "we check curve and see that lowest rmse is at k=7\n",
      "\n",
      "Can also use gridsearch to check best value of k\n",
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
      "\n",
      "knn = neighbors.KNeighborsRegressor()\n",
      "\n",
      "model = GridSearchCV(knn, params, cv=5)\n",
      "model.fit(x_train,y_train)\n",
      "model.best_params_\n",
      "\n",
      "\n",
      "Predictions on test dataset\n",
      "\n",
      "#reading test and submission files\n",
      "test = pd.read_csv('test.csv')\n",
      "submission = pd.read_csv('SampleSubmission.csv')\n",
      "submission['Item_Identifier'] = test['Item_Identifier']\n",
      "submission['Outlet_Identifier'] = test['Outlet_Identifier']\n",
      "\n",
      "#preprocessing test dataset\n",
      "test.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1, inplace=True)\n",
      "test['Item_Weight'].fillna(mean, inplace =True)\n",
      "test = pd.get_dummies(test)\n",
      "test_scaled = scaler.fit_transform(test)\n",
      "test = pd.DataFrame(test_scaled)\n",
      "\n",
      "#predicting on the test set and creating submission file\n",
      "predict = model.predict(test)\n",
      "submission['Item_Outlet_Sales'] = predict\n",
      "submission.to_csv('submit_file.csv',index=False)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN for classification\n",
      "\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler  \n",
      "scaler = StandardScaler()  \n",
      "scaler.fit(X_train)\n",
      "\n",
      "X_train = scaler.transform(X_train)  \n",
      "X_test = scaler.transform(X_test) \n",
      "\n",
      "\n",
      "from sklearn.neighbors import KNeighborsClassifier  \n",
      "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
      "classifier.fit(X_train, y_train)  \n",
      "\n",
      "\n",
      "y_pred = classifier.predict(X_test)  \n",
      "from sklearn.metrics import classification_report, confusion_matrix  \n",
      "print(confusion_matrix(y_test, y_pred))  \n",
      "print(classification_report(y_test, y_pred))  \n",
      "\n",
      "error = []\n",
      "\n",
      "# Calculating error for K values between 1 and 40\n",
      "for i in range(1, 40):  \n",
      "    knn = KNeighborsClassifier(n_neighbors=i)\n",
      "    knn.fit(X_train, y_train)\n",
      "    pred_i = knn.predict(X_test)\n",
      "    error.append(np.mean(pred_i != y_test))\n",
      "\n",
      "plt.figure(figsize=(12, 6))  \n",
      "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',  \n",
      "         markerfacecolor='blue', markersize=10)\n",
      "plt.title('Error Rate K Value')  \n",
      "plt.xlabel('K Value')  \n",
      "plt.ylabel('Mean Error') \n",
      "\n",
      "\n",
      "we could check from the graph that optimal value of k is 5\n"
     ]
    }
   ],
   "source": [
    "# Absolute path of current working directory: \"C:\\Users\\1334126\\Desktop\\DataCamp Learnings\\Python Learnings\\Week1-Python\"\n",
    "# File '12.knn.txt' is in another directory: \"C:\\Users\\1334126\\Desktop\\DataCamp Learnings\\New folder\"\n",
    "# Hence you go two levels up at \"C:\\Users\\1334126\\Desktop\\DataCamp Learnings\" from your current working directory using \"..\\\\\" \n",
    "# twice and then to \"New Folder\" where the 12.knn.txt file exists\n",
    "\n",
    "f = open(\"..\\\\..\\\\New Folder\\\\12.knn.txt\", \"r\")\n",
    "print(f.read())\n",
    "\n",
    "# Else you can give the full path, whic is not desirable\n",
    "\n",
    "f = open('C:\\\\Users\\\\1334126\\\\Desktop\\\\DataCamp Learnings\\\\New folder\\\\12.knn.txt', 'r')\n",
    "print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
